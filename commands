
- docker-compose up -d
- docker-compose down

- kafka-topics --list --bootstrap-server broker:29092
- kafka-topics --delete --topic gps_data --bootstrap-server broker:29092
- kafka-console-consumer --bootstrap-server broker:29092 --topic emergency_data --from-beginning


- docker exec -it smart-city-spark-master-1 spark-submit \
--master spark://spark-master:7077 \
--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.hadoop:hadoop-aws:3.3.1,com.amazonaws:aws-java-sdk:1.11.469 \
jobs/spark-city.py



IAC flow

- create s3 bucket spark-streaming-data
- Disable Block pubic access option
- Add policy in permission section 

{
    "Version": "2012-10-17",
    "Id": "Policy1708964691216",
    "Statement": [
        {
            "Sid": "Stmt1708964685647",
            "Effect": "Allow",
            "Principal": "*",
            "Action": [
                "s3:GetObject",
                "s3:PutObject",
                "s3:PutObjectAcl"
            ],
            "Resource": "arn:aws:s3:::smartcity-spark-streaming-data/*"
        }
    ]
}

- create an IAM user SmartCityUser and use its access and secret key as config
